{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Volumes/TOB_WD2/Data_Analysis/DataFrames\" + \"/\"\n",
    "lineages = root + \"/Tracking/Output_Lineages\" + \"/\"\n",
    "\n",
    "def conc_lineage_df(in_dir):\n",
    "    dataframes = []\n",
    "    for subdir, dirs, files in os.walk(in_dir):\n",
    "        for file in files:\n",
    "            if not file.startswith(\".\"):\n",
    "                filepath = subdir + os.sep + file  \n",
    "                if filepath.endswith(\".csv\"):\n",
    "                    single_df = pd.read_csv(filepath)\n",
    "                    dataframes.append(single_df)    \n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    df = pd.concat(dataframes)\n",
    "    return df\n",
    "     \n",
    "lineages_df = conc_lineage_df(lineages)\n",
    "times_df = pd.read_csv(root + \"MasterDataFrame_Times.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20200724' '20190227' '20190618' '20190827' '20200731' '20200730'\n",
      " '20200807' '20200728']\n"
     ]
    }
   ],
   "source": [
    "# Preparing times for merging \n",
    "def parent_dataset(x):\n",
    "        datasets = [\n",
    "            \"20190227-182447\", \n",
    "            \"20190618-conc\", \n",
    "            \"20190827-181922\",\n",
    "            \"20200724-201611\",\n",
    "            \"20200728-174144\", \n",
    "            \"20200730-190931\",\n",
    "            \"20200731-175845\",\n",
    "            \"20200806-164803\",\n",
    "            \"20200807-174159\"\n",
    "        ]\n",
    "\n",
    "        if x in datasets:\n",
    "            return x.split(\"-\")[0]\n",
    "\n",
    "        elif (x == \"20200802-104739\") or (x == \"20200803-181830\"):\n",
    "            return \"20200731\"\n",
    "        elif x == \"20200725-142832\":\n",
    "            return \"20200724\"\n",
    "        elif (x == \"20200809-114236\") or (x == \"20200810-225504\"):\n",
    "            return \"20200807\"\n",
    "        else:\n",
    "            print(\"Does not apply?: \" + x)\n",
    "\n",
    "def correct_timepoints(x):\n",
    "    subexperiment_key = x.Subexperiment\n",
    "    timepoint = x.Timepoint\n",
    "    timepoint_dir = {\"20200725-142832\": 93, \n",
    "                     \"20200802-104739\": 225, \n",
    "                     \"20200803-181830\": 374, \n",
    "                     \"20200809-114236\": 199, \n",
    "                     \"20200810-225504\": 378\n",
    "                    }\n",
    "    if subexperiment_key in timepoint_dir:\n",
    "        new_timepoint = timepoint + timepoint_dir[subexperiment_key]\n",
    "        return new_timepoint\n",
    "    else:\n",
    "        return timepoint\n",
    "\n",
    "            \n",
    "lineages_df.rename(columns = {\"Experiment\": \"Subexperiment\"}, inplace = True)\n",
    "lineages_df[\"Experiment\"] = lineages_df.Subexperiment.apply(parent_dataset)\n",
    "print(lineages_df.Experiment.unique())\n",
    "times_df[\"Subexperiment\"] = times_df.LowZoom_ID.str.split(\"_\").str.get(0)\n",
    "times_df[\"Experiment\"] = times_df.Subexperiment.apply(parent_dataset)  \n",
    "\n",
    "times_df[\"Timepoint\"] = times_df.LowZoom_ID.apply(lambda x: int(x[-4:]))\n",
    "times_df[\"Timepoint\"] = times_df.apply(correct_timepoints, axis = 1)\n",
    "times_df[\"Position\"] = times_df.LowZoom_ID.apply(lambda x: int(x[-7]))\n",
    "destination_times = root + \"MasterDataFrame_Times_II.csv\"\n",
    "times_df.to_csv(destination_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20200724-201611' '20200725-142832' '20190227-182447' '20190618-conc'\n",
      " '20190827-181922' '20200731-175845' '20200802-104739' '20200803-181830'\n",
      " '20200730-190931' '20200807-174159' '20200809-114236' '20200728-174144']\n",
      "['20190227-182447' '20190827-181922' '20200724-201611' '20200725-142832'\n",
      " '20200728-174144' '20200730-190931' '20200731-175845' '20200802-104739'\n",
      " '20200803-181830' '20200806-164803' '20200807-174159' '20200809-114236'\n",
      " '20200810-225504' '20190618-conc']\n"
     ]
    }
   ],
   "source": [
    "print(lineages_df.Subexperiment.unique())\n",
    "print(times_df.Subexperiment.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = times_df.merge(lineages_df, how = \"inner\", on = [\"Timepoint\", \"Experiment\", \"Subexperiment\", \"Position\"]) \n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "destination = root + \"MasterDataFrame_MergeLineagesTimes.csv\"\n",
    "df.to_csv(destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Position</th>\n",
       "      <th>Max_No_of_Generations</th>\n",
       "      <th>Number_of_Source_IDs</th>\n",
       "      <th>Number_of_Sister_IDs</th>\n",
       "      <th>Number_of_Cousin_IDs</th>\n",
       "      <th>Number_of_Mother_IDs</th>\n",
       "      <th>Number_of_Aunt_IDs</th>\n",
       "      <th>Number_of_Grandmother_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190227</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>652</td>\n",
       "      <td>580</td>\n",
       "      <td>531</td>\n",
       "      <td>627</td>\n",
       "      <td>563</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190227</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>318</td>\n",
       "      <td>238</td>\n",
       "      <td>174</td>\n",
       "      <td>264</td>\n",
       "      <td>193</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190827</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>462</td>\n",
       "      <td>400</td>\n",
       "      <td>372</td>\n",
       "      <td>436</td>\n",
       "      <td>400</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190827</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1079</td>\n",
       "      <td>628</td>\n",
       "      <td>420</td>\n",
       "      <td>848</td>\n",
       "      <td>533</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200724</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>523</td>\n",
       "      <td>312</td>\n",
       "      <td>125</td>\n",
       "      <td>380</td>\n",
       "      <td>151</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200724</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>455</td>\n",
       "      <td>262</td>\n",
       "      <td>114</td>\n",
       "      <td>317</td>\n",
       "      <td>150</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200728</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200728</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200730</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200730</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200731</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>546</td>\n",
       "      <td>468</td>\n",
       "      <td>403</td>\n",
       "      <td>526</td>\n",
       "      <td>462</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200731</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>303</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>146</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200807</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200807</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190618</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>654</td>\n",
       "      <td>520</td>\n",
       "      <td>490</td>\n",
       "      <td>621</td>\n",
       "      <td>537</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190618</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>595</td>\n",
       "      <td>466</td>\n",
       "      <td>365</td>\n",
       "      <td>552</td>\n",
       "      <td>438</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Position  Max_No_of_Generations  Number_of_Source_IDs  \\\n",
       "0  20190227         1                    7.0                   652   \n",
       "0  20190227         2                    5.0                   318   \n",
       "0  20190827         1                    7.0                   462   \n",
       "0  20190827         2                    8.0                  1079   \n",
       "0  20200724         1                    6.0                   523   \n",
       "0  20200724         2                    5.0                   455   \n",
       "0  20200728         1                    NaN                     0   \n",
       "0  20200728         2                    2.0                    59   \n",
       "0  20200730         1                    2.0                   134   \n",
       "0  20200730         2                    NaN                     0   \n",
       "0  20200731         1                    8.0                   546   \n",
       "0  20200731         2                    6.0                   303   \n",
       "0  20200807         1                    NaN                     0   \n",
       "0  20200807         2                    4.0                   131   \n",
       "0  20190618         1                    8.0                   654   \n",
       "0  20190618         2                    7.0                   595   \n",
       "\n",
       "   Number_of_Sister_IDs  Number_of_Cousin_IDs  Number_of_Mother_IDs  \\\n",
       "0                   580                   531                   627   \n",
       "0                   238                   174                   264   \n",
       "0                   400                   372                   436   \n",
       "0                   628                   420                   848   \n",
       "0                   312                   125                   380   \n",
       "0                   262                   114                   317   \n",
       "0                     0                     0                     0   \n",
       "0                    20                     0                    33   \n",
       "0                    12                     0                    24   \n",
       "0                     0                     0                     0   \n",
       "0                   468                   403                   526   \n",
       "0                    90                    20                   146   \n",
       "0                     0                     0                     0   \n",
       "0                    40                     7                    71   \n",
       "0                   520                   490                   621   \n",
       "0                   466                   365                   552   \n",
       "\n",
       "   Number_of_Aunt_IDs  Number_of_Grandmother_IDs  \n",
       "0                 563                        579  \n",
       "0                 193                        203  \n",
       "0                 400                        406  \n",
       "0                 533                        617  \n",
       "0                 151                        171  \n",
       "0                 150                        174  \n",
       "0                   0                          0  \n",
       "0                   0                          0  \n",
       "0                   0                          0  \n",
       "0                   0                          0  \n",
       "0                 462                        490  \n",
       "0                  23                         44  \n",
       "0                   0                          0  \n",
       "0                  14                         23  \n",
       "0                 537                        570  \n",
       "0                 438                        477  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quality control meta statistics after merging \n",
    "# Times and Lineages\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "def get_lineage_statistics(dataframe = df):\n",
    "    dataframelist = dataframe.Experiment.unique()\n",
    "    positions = [1, 2]\n",
    "    dataframes_for_concat = []\n",
    "    for data_name in dataframelist:\n",
    "        for position in positions:    \n",
    "\n",
    "            data = dataframe[(dataframe[\"Experiment\"] == data_name) & (dataframe[\"Position\"] == position)]\n",
    "            dataset = data_name\n",
    "            position = position\n",
    "            max_generation = data.Generation.max()\n",
    "            No_of_source_ids = data.Source_ID.dropna().shape[0]\n",
    "            No_of_sister_ids = data.Sister_ID.dropna().shape[0]\n",
    "            No_of_mother_ids = data.Mother_ID.dropna().shape[0]\n",
    "            No_of_aunt_ids = data.Aunt_ID.dropna().shape[0]\n",
    "            No_of_cousin_ids = data.Cousin_ID.dropna().shape[0]\n",
    "            No_of_grandmother_ids = data.Grandmother_ID.dropna().shape[0]\n",
    "\n",
    "            statistics_dict = {\"Dataset\": dataset, \n",
    "                               \"Position\": position, \n",
    "                               \"Max_No_of_Generations\": max_generation,\n",
    "                               \"Number_of_Source_IDs\": No_of_source_ids,\n",
    "                               \"Number_of_Sister_IDs\": No_of_sister_ids,\n",
    "                               \"Number_of_Cousin_IDs\": No_of_cousin_ids,\n",
    "                               \"Number_of_Mother_IDs\": No_of_mother_ids,\n",
    "                               \"Number_of_Aunt_IDs\": No_of_aunt_ids,\n",
    "                               \"Number_of_Grandmother_IDs\": No_of_grandmother_ids,\n",
    "                              }\n",
    "            df = pd.DataFrame(statistics_dict, index = [0])\n",
    "            dataframes_for_concat.append(df)\n",
    "    \n",
    "    final_df = pd.concat(dataframes_for_concat)\n",
    "    return final_df\n",
    "\n",
    "statistics_df = get_lineage_statistics()\n",
    "statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating cell cycles.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>LowZoom_ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Experiment_StartTime_mins</th>\n",
       "      <th>Experiment_Time_mins</th>\n",
       "      <th>Subexperiment</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Position</th>\n",
       "      <th>Track_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Mother_ID</th>\n",
       "      <th>Grandmother_ID</th>\n",
       "      <th>Sister_ID</th>\n",
       "      <th>Seen_sister</th>\n",
       "      <th>Aunt_ID</th>\n",
       "      <th>Cousin_ID</th>\n",
       "      <th>Random_ID</th>\n",
       "      <th>Seen_granny</th>\n",
       "      <th>Cell_Cycle_mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>2019/06/22 10:11:53</td>\n",
       "      <td>20190618-conc_LowZoom--W0000--P0001-T0370</td>\n",
       "      <td>1.561191e+09</td>\n",
       "      <td>1.560879e+09</td>\n",
       "      <td>5194.05</td>\n",
       "      <td>20190618-conc</td>\n",
       "      <td>20190618</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2032.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>3207</td>\n",
       "      <td>False</td>\n",
       "      <td>1282.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>2019/06/22 10:11:53</td>\n",
       "      <td>20190618-conc_LowZoom--W0000--P0001-T0370</td>\n",
       "      <td>1.561191e+09</td>\n",
       "      <td>1.560879e+09</td>\n",
       "      <td>5194.05</td>\n",
       "      <td>20190618-conc</td>\n",
       "      <td>20190618</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2941.0</td>\n",
       "      <td>2928.0</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>666</td>\n",
       "      <td>True</td>\n",
       "      <td>980.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>2019/06/22 10:11:53</td>\n",
       "      <td>20190618-conc_LowZoom--W0000--P0001-T0370</td>\n",
       "      <td>1.561191e+09</td>\n",
       "      <td>1.560879e+09</td>\n",
       "      <td>5194.05</td>\n",
       "      <td>20190618-conc</td>\n",
       "      <td>20190618</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>4433.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>286</td>\n",
       "      <td>False</td>\n",
       "      <td>756.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>2019/06/22 10:11:53</td>\n",
       "      <td>20190618-conc_LowZoom--W0000--P0001-T0370</td>\n",
       "      <td>1.561191e+09</td>\n",
       "      <td>1.560879e+09</td>\n",
       "      <td>5194.05</td>\n",
       "      <td>20190618-conc</td>\n",
       "      <td>20190618</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4492.0</td>\n",
       "      <td>4482.0</td>\n",
       "      <td>4512.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4528.0</td>\n",
       "      <td>(4554, 4538)</td>\n",
       "      <td>13824</td>\n",
       "      <td>True</td>\n",
       "      <td>756.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>2019/06/22 10:11:53</td>\n",
       "      <td>20190618-conc_LowZoom--W0000--P0001-T0370</td>\n",
       "      <td>1.561191e+09</td>\n",
       "      <td>1.560879e+09</td>\n",
       "      <td>5194.05</td>\n",
       "      <td>20190618-conc</td>\n",
       "      <td>20190618</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5123.0</td>\n",
       "      <td>5113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15060</td>\n",
       "      <td>False</td>\n",
       "      <td>822.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time                                 LowZoom_ID  \\\n",
       "5906  2019/06/22 10:11:53  20190618-conc_LowZoom--W0000--P0001-T0370   \n",
       "5907  2019/06/22 10:11:53  20190618-conc_LowZoom--W0000--P0001-T0370   \n",
       "5908  2019/06/22 10:11:53  20190618-conc_LowZoom--W0000--P0001-T0370   \n",
       "5909  2019/06/22 10:11:53  20190618-conc_LowZoom--W0000--P0001-T0370   \n",
       "5910  2019/06/22 10:11:53  20190618-conc_LowZoom--W0000--P0001-T0370   \n",
       "\n",
       "         Timestamp  Experiment_StartTime_mins  Experiment_Time_mins  \\\n",
       "5906  1.561191e+09               1.560879e+09               5194.05   \n",
       "5907  1.561191e+09               1.560879e+09               5194.05   \n",
       "5908  1.561191e+09               1.560879e+09               5194.05   \n",
       "5909  1.561191e+09               1.560879e+09               5194.05   \n",
       "5910  1.561191e+09               1.560879e+09               5194.05   \n",
       "\n",
       "      Subexperiment Experiment  Timepoint  Position  Track_ID  ...  \\\n",
       "5906  20190618-conc   20190618        370         1         4  ...   \n",
       "5907  20190618-conc   20190618        370         1         5  ...   \n",
       "5908  20190618-conc   20190618        370         1         6  ...   \n",
       "5909  20190618-conc   20190618        370         1         6  ...   \n",
       "5910  20190618-conc   20190618        370         1         7  ...   \n",
       "\n",
       "      Generation  Mother_ID Grandmother_ID  Sister_ID  Seen_sister  Aunt_ID  \\\n",
       "5906           7     2032.0         1993.0     2042.0        False   2003.0   \n",
       "5907           6     2941.0         2928.0     2970.0         True   2995.0   \n",
       "5908           8     4423.0         4400.0     4433.0        False   4410.0   \n",
       "5909           8     4492.0         4482.0     4512.0         True   4528.0   \n",
       "5910           7     5123.0         5113.0        NaN          NaN   5146.0   \n",
       "\n",
       "         Cousin_ID  Random_ID  Seen_granny  Cell_Cycle_mins  \n",
       "5906          2016       3207        False      1282.516667  \n",
       "5907           NaN        666         True       980.366667  \n",
       "5908           NaN        286        False       756.266667  \n",
       "5909  (4554, 4538)      13824         True       756.266667  \n",
       "5910           NaN      15060        False       822.583333  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cell_cycle(x, dataframe):\n",
    "    daughter_time = x.Experiment_Time_mins\n",
    "    if x.Generation < 2:\n",
    "        return None\n",
    "    else:\n",
    "        mother_row = dataframe.loc[\n",
    "            (dataframe.Experiment == x.Experiment) &\n",
    " #           (dataframe.Subexperiment == x.Subexperiment) & #mothers can be in older subexperiments!\n",
    "            (dataframe.Position == x.Position) &\n",
    "            (dataframe.Source_ID == x.Mother_ID)\n",
    "        ]\n",
    "        if mother_row[\"Experiment_Time_mins\"].shape[0] == 1:   \n",
    "            mother_time = mother_row[\"Experiment_Time_mins\"].item()\n",
    "            cell_cycle = daughter_time - mother_time\n",
    "            return cell_cycle\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "df[\"Cell_Cycle_mins\"] = df.apply(get_cell_cycle, dataframe = df, axis = 1)\n",
    "\n",
    "print(\"Finished calculating cell cycles.\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'LowZoom_ID', 'Timestamp', 'Experiment_StartTime_mins',\n",
       "       'Experiment_Time_mins', 'Subexperiment', 'Experiment', 'Timepoint',\n",
       "       'Position', 'Track_ID', 'Source_ID', 'Splitting_event', 'Lineage',\n",
       "       'Track_Coordinate_X', 'Track_Coordinate_Y', 'Frame', 'Dataset',\n",
       "       'Generation', 'Mother_ID', 'Grandmother_ID', 'Sister_ID', 'Seen_sister',\n",
       "       'Aunt_ID', 'Cousin_ID', 'Random_ID', 'Seen_granny', 'Cell_Cycle_mins'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to have consistent nomenclature of columns\n",
    "\n",
    "df = df.rename(columns = {\"Subexperiment\": \"Experiment\", \"Experiment\": \"Dataset\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Track_ID', 'Source_ID', 'Splitting_event', 'Lineage',\n",
       "       'Track_Coordinate_X', 'Track_Coordinate_Y', 'Frame', 'Generation',\n",
       "       'Mother_ID', 'Grandmother_ID', 'Sister_ID', 'Seen_sister', 'Aunt_ID',\n",
       "       'Cousin_ID', 'Random_ID', 'Seen_granny', 'Delta_x', 'Delta_y',\n",
       "       'Delta_t', 'Cell_ID', 'LowZoom_ID', 'Dataset', 'Experiment', 'Position',\n",
       "       'Condition', 'Has_duplicate', 'X_px', 'Y_px', 'Timepoint', 'Time',\n",
       "       'Differentiation_mins', 'Differentiation_bins', 'Experiment_Time_mins',\n",
       "       'Chromatin_Dilation', 'Chromatin_Volume_um3', 'DNA_Volume_Threshold',\n",
       "       'MetaphasePlate_Length_um', 'MetaphasePlate_Width_um',\n",
       "       'Spindle_Angle_Degrees', 'Spindle_Aspect_Ratio',\n",
       "       'Spindle_DNA_Volume_Ratio', 'Spindle_Length_um', 'Spindle_Volume_um3',\n",
       "       'Spindle_Width_Avg_um', 'Tubulin_Spindle_Average_Intensity', 'Version',\n",
       "       'Cell_Volume_um3', 'SurfaceArea', 'Sphericity', 'Tubulin_Cell_Average',\n",
       "       'Tubulin_Cell_Minimum', 'Tubulin_Cell_Maximum', 'Tubulin_Cell_IntDen',\n",
       "       'Tubulin_mass_cell', 'Tubulin_mass_cell_norm', 'Tubulin_mass_spindle',\n",
       "       'Tubulin_mass_spindle_norm', 'Tubulin_mass_cytoplasm',\n",
       "       'Tubulin_mass_cytoplasm_norm', 'Tubulin_Cytop_Average',\n",
       "       'Tubulin_density_cytop_norm', 'Fraction_Tubulin_in_Spindle',\n",
       "       'Fraction_SpindleVol_in_Cell', 'Tubulin_Averages_Ratio',\n",
       "       'Tubulin_Averages_Cytop_Ratio', 'Tubulin_density_spindle_norm',\n",
       "       'SpindleVolume_ChromatinVolume_Ratio',\n",
       "       'CellSurfaceArea_CellVolume_Ratio', 'Cell_Volume_bin',\n",
       "       'CellSurfaceArea_CellVolume_bin', 'Spindle_Volume_bin',\n",
       "       'Spindle_Width_bin', 'Colour', 'States',\n",
       "       'Fraction_Tubulin_in_Spindle_P1mean',\n",
       "       'Fraction_Tubulin_in_Spindle_P1std',\n",
       "       'Fraction_Tubulin_in_Spindle_P2mean',\n",
       "       'Fraction_Tubulin_in_Spindle_P2std',\n",
       "       'Fraction_Tubulin_in_Spindle_BinNormP1',\n",
       "       'Fraction_SpindleVol_in_Cell_P1mean',\n",
       "       'Fraction_SpindleVol_in_Cell_P1std',\n",
       "       'Fraction_SpindleVol_in_Cell_P2mean',\n",
       "       'Fraction_SpindleVol_in_Cell_P2std',\n",
       "       'Fraction_SpindleVol_in_Cell_BinNormP1', 'Spindle_Volume_um3_P1mean',\n",
       "       'Spindle_Volume_um3_P1std', 'Spindle_Volume_um3_P2mean',\n",
       "       'Spindle_Volume_um3_P2std', 'Spindle_Volume_um3_BinNormP1', 'X_um',\n",
       "       'Y_um'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dataframe with morphometrics dataframe\n",
    "\n",
    "#SOMETHING DOESN'T WORK, THERE ARE CELL CYCLES WITHOUT LINEAGE WHICH IS IMPOSSIBLE\n",
    "#ALSO, reduced number of i.e. CV is because that's the one which have a lineage\n",
    "\n",
    "sub_df = df[['Time', 'LowZoom_ID', 'Experiment_Time_mins', 'Experiment', 'Dataset',\n",
    "       'Timepoint', 'Position', 'Track_ID', 'Source_ID', 'Splitting_event',\n",
    "       'Lineage', 'Track_Coordinate_X', 'Track_Coordinate_Y', 'Frame',\n",
    "       'Dataset', 'Generation', 'Mother_ID', 'Grandmother_ID', 'Sister_ID',\n",
    "       'Seen_sister', 'Aunt_ID', 'Cousin_ID', 'Random_ID', 'Seen_granny']] ######## TEST Source_ID and Dataset and Position or so\n",
    "matches_df = pd.read_csv(root + \"MasterDataFrame_MatchesLineages.csv\")\n",
    "matches_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Data columns not unique: Index(['Time', 'LowZoom_ID', 'Experiment_Time_mins', 'Experiment', 'Dataset',\n       'Dataset', 'Timepoint', 'Position', 'Track_ID', 'Source_ID',\n       'Splitting_event', 'Lineage', 'Track_Coordinate_X',\n       'Track_Coordinate_Y', 'Frame', 'Dataset', 'Dataset', 'Generation',\n       'Mother_ID', 'Grandmother_ID', 'Sister_ID', 'Seen_sister', 'Aunt_ID',\n       'Cousin_ID', 'Random_ID', 'Seen_granny'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f06eadcc86a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatches_CC_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatches_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches_CC_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmatches_CC_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# note this function has side effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                     )\n\u001b[1;32m   1221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcommon_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data columns not unique: {repr(common_cols)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_on\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMergeError\u001b[0m: Data columns not unique: Index(['Time', 'LowZoom_ID', 'Experiment_Time_mins', 'Experiment', 'Dataset',\n       'Dataset', 'Timepoint', 'Position', 'Track_ID', 'Source_ID',\n       'Splitting_event', 'Lineage', 'Track_Coordinate_X',\n       'Track_Coordinate_Y', 'Frame', 'Dataset', 'Dataset', 'Generation',\n       'Mother_ID', 'Grandmother_ID', 'Sister_ID', 'Seen_sister', 'Aunt_ID',\n       'Cousin_ID', 'Random_ID', 'Seen_granny'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "matches_CC_df = pd.merge(sub_df, matches_df, how = \"outer\")\n",
    "print(matches_CC_df.shape)\n",
    "matches_CC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_CC_df.to_csv(root + \"MasterDataFrame_MatchesLineagesWithCellCycles.csv\")\n",
    "print(\"Saved the BIG FINAL DATAFRAME.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages_df.to_csv(root + \"MasterDataFrame_Lineages.csv\")\n",
    "print(\"Finished compilation of concatenated lineages dataframe: {}\".format(root + \"MasterDataFrame_Lineages.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
