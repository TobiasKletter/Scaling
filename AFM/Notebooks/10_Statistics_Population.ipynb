{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import sklearn.linear_model\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the df Pluripotent: (1247, 74)\n",
      "The shape of the df Differentiation: (3576, 74)\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/Volumes/TOB_WD2/Data_Analysis/DataFrames\" + \"/\"\n",
    "\n",
    "# load data\n",
    "\n",
    "df = pd.read_csv(root_dir + \"MasterDataFrame_Population_Morphometry_FilteredForStatistics.csv\") # only Spindle3D overlap \n",
    "#df = pd.read_csv(root_dir + \"MasterDataFrame_Population_Morphometry.csv\") # not filtered\n",
    "\n",
    "\n",
    "df_p1 = df[df.Condition == \"1_Pluripotent\"]\n",
    "df_p2 = df[df.Condition == \"2_Differentiation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition          Differentiation_bins\n",
       "1_Pluripotent      (2880, 5760]             690\n",
       "                   (5760, 8640]             440\n",
       "                   (0, 2880]                117\n",
       "2_Differentiation  (2880, 5760]            1917\n",
       "                   (5760, 8640]            1300\n",
       "                   (0, 2880]                359\n",
       "Name: Differentiation_bins, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Condition\").Differentiation_bins.value_counts() ##### always check whether filtered or not! #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell_Volume_bin   Condition        \n",
       "(1000.0, 1500.0]  1_Pluripotent        1452.621800\n",
       "                  2_Differentiation    1349.798000\n",
       "(1500.0, 2000.0]  1_Pluripotent        1851.392860\n",
       "                  2_Differentiation    1786.129138\n",
       "(2000.0, 2500.0]  1_Pluripotent        2277.983975\n",
       "                  2_Differentiation    2227.331843\n",
       "(2500.0, 3000.0]  1_Pluripotent        2753.341602\n",
       "                  2_Differentiation    2712.582751\n",
       "(3000.0, 3500.0]  1_Pluripotent        3190.007983\n",
       "                  2_Differentiation    3166.228022\n",
       "(3500.0, 4000.0]  1_Pluripotent        3660.294763\n",
       "                  2_Differentiation    3707.985900\n",
       "Name: Cell_Volume_um3, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Cell_Volume_bin\", \"Condition\"]).Cell_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell_Volume_bin   Condition        \n",
       "(1000.0, 1500.0]  1_Pluripotent         16.512376\n",
       "                  2_Differentiation    112.204719\n",
       "(1500.0, 2000.0]  1_Pluripotent        118.671532\n",
       "                  2_Differentiation    134.741782\n",
       "(2000.0, 2500.0]  1_Pluripotent        140.631075\n",
       "                  2_Differentiation    143.605633\n",
       "(2500.0, 3000.0]  1_Pluripotent        137.954190\n",
       "                  2_Differentiation    138.231398\n",
       "(3000.0, 3500.0]  1_Pluripotent        133.722375\n",
       "                  2_Differentiation    125.963980\n",
       "(3500.0, 4000.0]  1_Pluripotent        127.199293\n",
       "                  2_Differentiation    154.466344\n",
       "Name: Cell_Volume_um3, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Cell_Volume_bin\", \"Condition\"]).Cell_Volume_um3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell_Volume_bin   Condition        \n",
       "(1000.0, 1500.0]  1_Pluripotent        219.090625\n",
       "                  2_Differentiation    178.085186\n",
       "(1500.0, 2000.0]  1_Pluripotent        259.897204\n",
       "                  2_Differentiation    214.679175\n",
       "(2000.0, 2500.0]  1_Pluripotent        305.274442\n",
       "                  2_Differentiation    251.250123\n",
       "(2500.0, 3000.0]  1_Pluripotent        349.343680\n",
       "                  2_Differentiation    305.519395\n",
       "(3000.0, 3500.0]  1_Pluripotent        386.977285\n",
       "                  2_Differentiation    361.889595\n",
       "(3500.0, 4000.0]  1_Pluripotent        445.860964\n",
       "                  2_Differentiation    395.506250\n",
       "Name: Spindle_Volume_um3, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Cell_Volume_bin\", \"Condition\"]).Spindle_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell_Volume_bin   Condition        \n",
       "(1000.0, 1500.0]  1_Pluripotent        19.497190\n",
       "                  2_Differentiation    35.027069\n",
       "(1500.0, 2000.0]  1_Pluripotent        47.407925\n",
       "                  2_Differentiation    39.047369\n",
       "(2000.0, 2500.0]  1_Pluripotent        51.852659\n",
       "                  2_Differentiation    48.373851\n",
       "(2500.0, 3000.0]  1_Pluripotent        57.578790\n",
       "                  2_Differentiation    54.913658\n",
       "(3000.0, 3500.0]  1_Pluripotent        55.137136\n",
       "                  2_Differentiation    62.724359\n",
       "(3500.0, 4000.0]  1_Pluripotent        63.267413\n",
       "                  2_Differentiation    50.774193\n",
       "Name: Spindle_Volume_um3, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Cell_Volume_bin\", \"Condition\"]).Spindle_Volume_um3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell_Volume_bin   Condition        \n",
       "(1000.0, 1500.0]  1_Pluripotent        47.842326\n",
       "                  2_Differentiation    43.709415\n",
       "(1500.0, 2000.0]  1_Pluripotent        46.805505\n",
       "                  2_Differentiation    42.551425\n",
       "(2000.0, 2500.0]  1_Pluripotent        46.342361\n",
       "                  2_Differentiation    42.383994\n",
       "(2500.0, 3000.0]  1_Pluripotent        45.761932\n",
       "                  2_Differentiation    42.206494\n",
       "(3000.0, 3500.0]  1_Pluripotent        44.794360\n",
       "                  2_Differentiation    43.272582\n",
       "(3500.0, 4000.0]  1_Pluripotent        44.471976\n",
       "                  2_Differentiation    42.107189\n",
       "Name: Fraction_Tubulin_in_Spindle, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Cell_Volume_bin\", \"Condition\"]).Fraction_Tubulin_in_Spindle.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell_Volume_bin   Condition        \n",
       "(1000.0, 1500.0]  1_Pluripotent        3.053103\n",
       "                  2_Differentiation    4.762204\n",
       "(1500.0, 2000.0]  1_Pluripotent        5.816360\n",
       "                  2_Differentiation    4.461063\n",
       "(2000.0, 2500.0]  1_Pluripotent        4.634863\n",
       "                  2_Differentiation    4.684790\n",
       "(2500.0, 3000.0]  1_Pluripotent        4.336217\n",
       "                  2_Differentiation    4.826551\n",
       "(3000.0, 3500.0]  1_Pluripotent        3.781280\n",
       "                  2_Differentiation    4.497058\n",
       "(3500.0, 4000.0]  1_Pluripotent        3.854429\n",
       "                  2_Differentiation    4.026340\n",
       "Name: Fraction_Tubulin_in_Spindle, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Cell_Volume_bin\", \"Condition\"]).Fraction_Tubulin_in_Spindle.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Cell_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Cell_Volume_um3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).SurfaceArea.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).SurfaceArea.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Spindle_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Spindle_Volume_um3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Fraction_Tubulin_in_Spindle.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Fraction_Tubulin_in_Spindle.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Fraction_SpindleVol_in_Cell.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Fraction_SpindleVol_in_Cell.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Tubulin_density_spindle_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Tubulin_density_spindle_norm.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Tubulin_density_cytop_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\", \"Condition\"]).Tubulin_density_cytop_norm.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "# also test regression via scipy.stats.linregress(x, y) !!!\n",
    "\n",
    "def linear_fit(dataframe_list, independent_column, dependent_column): \n",
    "    for dataframe in dataframe_list:\n",
    "        dataframe = dataframe[~dataframe[independent_column].isna() & ~dataframe[dependent_column].isna()]\n",
    "        \n",
    "        dataframe_name = dataframe.Condition.head(1)\n",
    "        length = dataframe.shape[0]\n",
    "\n",
    "        X = dataframe[independent_column].values.reshape(length, 1)\n",
    "        y = dataframe[dependent_column].values.reshape(length, 1)\n",
    "\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(X, y)\n",
    "        y_predicted = regr.predict(X)\n",
    "\n",
    "        # model evaluation\n",
    "        rmse = mean_squared_error(y, y_predicted)\n",
    "        R2 = r2_score(y, y_predicted)\n",
    "        slope = regr.coef_\n",
    "        interc = regr.intercept_\n",
    "\n",
    "        print(\n",
    "            \"The linear fit for x = {} vs y = {} in {}: y = {} x +- {}. R2 = {}, RMSE = {}.\".format(\n",
    "                dependent_column, \n",
    "                independent_column,\n",
    "                dataframe_name, slope, interc, R2, rmse\n",
    "            )\n",
    "        )\n",
    "    return rmse, R2, slope, interc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non - linear regression\n",
    "\n",
    "def power_law(x, a, b):\n",
    "    # x = a * x ^ b\n",
    "    return a * np.power(x, b)\n",
    "\n",
    "# return parameters (pars) a and b, and the covariance (cov)\n",
    "def curve_fitting(dataframe, independent_variable, dependent_variable):\n",
    "    dataframe = dataframe[[independent_variable, dependent_variable]].dropna()\n",
    "    pars, cov = curve_fit(\n",
    "        f = power_law, \n",
    "        ydata = dataframe[dependent_variable], \n",
    "        xdata = dataframe[independent_variable], \n",
    "        p0 = [0, 0], \n",
    "        bounds = (-np.inf, np.inf), \n",
    "        absolute_sigma = True\n",
    "    )\n",
    "    # Get the standard deviations of the parameters (square roots of the # diagonal of the covariance)\n",
    "    # SEEMS LIKE THIS IS THE STANDARD ERROR? \n",
    "    stdevs = np.sqrt(np.diag(cov))\n",
    "    # Calculate the residuals\n",
    "    res = dataframe[dependent_variable] - power_law(dataframe[independent_variable], *pars)\n",
    "    print(\"Power law between {} (independent var) and {}, factor a = \".format(independent_variable, dependent_variable) + str(pars[0]) + \" +- \" + str(stdevs[0]))\n",
    "    print(\"exponent b= \" + str(pars[1]) + \" +- \" + str(stdevs[1]))\n",
    "    return pars, cov, stdevs, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "def correlation(dataframe_list, independent_column, dependent_column):\n",
    "    for dataframe in dataframe_list:\n",
    "        dataframe_name = dataframe.Condition.head(1)\n",
    "        spearman = stats.spearmanr(\n",
    "            dataframe[independent_column], \n",
    "            dataframe[dependent_column], \n",
    "            nan_policy = 'omit')\n",
    "        print(\n",
    "            \"Spearman correlation for x = {} vs y = {} in {}: {}.\".format(\n",
    "                dependent_column, \n",
    "                independent_column,\n",
    "                dataframe_name, spearman\n",
    "            )\n",
    "        )\n",
    "        \n",
    "def pearson_correlation(dataframe_list, independent_column, dependent_column):\n",
    "    for dataframe in dataframe_list:\n",
    "        dataframe_name = dataframe.Condition.head(1)\n",
    "        spearman = stats.pearsonr(\n",
    "            dataframe[independent_column], \n",
    "            dataframe[dependent_column], \n",
    "            )\n",
    "        print(\n",
    "            \"Pearson correlation for x = {} vs y = {} in {}: {}.\".format(\n",
    "                dependent_column, \n",
    "                independent_column,\n",
    "                dataframe_name, spearman\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping correlations\n",
    "\n",
    "def bootstrap_correlation(dataframe_list, variable_1, variable_2, iterations = 1000, n_subsampling = 500):\n",
    "\n",
    "    corr_dataframe_list = []\n",
    "    for dataframe in dataframe_list:\n",
    "        dataframe = dataframe[[variable_1, variable_2, \"Condition\"]].dropna()\n",
    "        condition = dataframe.Condition.head(1).item()\n",
    "        print(condition)\n",
    "        coefficient_lst = []\n",
    "        for i in range(iterations):\n",
    "            data_sample = dataframe.sample(n_subsampling, replace = True)\n",
    "            spearman = data_sample[variable_1].corr(\n",
    "                data_sample[variable_2], \n",
    "                method = 'spearman'\n",
    "            )\n",
    "            coefficient_lst.append(spearman)\n",
    "            print(\n",
    "                \"Sampled Spearman's correlation coefficient: {}\".format(spearman)\n",
    "            )\n",
    "        coefficient_df = pd.DataFrame(coefficient_lst)\n",
    "        coefficient_df[\"Condition\"] = condition\n",
    "        corr_dataframe_list.append(coefficient_df)\n",
    "    df = pd.concat(corr_dataframe_list)\n",
    "    df = df.rename({0: 'Spearman_coefficient'.format(variable_1, variable_2)}, axis = 1) \n",
    "    df[\"Colour\"] = df.Condition.apply(\n",
    "        lambda x: \"#274754\" if x == \"2_Differentiation\" else \"#E8C468\"\n",
    "    )\n",
    "    print(\"Concatenated dataframe containing bootstrapped correlation coefficients.\")\n",
    "    df.to_csv(root_dir + 'BOOTSTRAP_Spearman_{}_{}.csv'.format(variable_1, variable_2))\n",
    "    print(\"Saved dataframe in: \" + root_dir)\n",
    "    return df\n",
    "\n",
    "SVdensity_bootstrap = bootstrap_correlation(\n",
    "    dataframe_list = [df_p1, df_p2], \n",
    "    variable_1 = \"Tubulin_density_spindle_norm\", \n",
    "    variable_2 = \"Spindle_Volume_um3\", \n",
    "    iterations = 1000, \n",
    "    n_subsampling = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of variation\n",
    "\n",
    "def CoV(measurement, condition_1, condition_2):\n",
    "    CoV_p1 = scipy.stats.variation(condition_1[measurement], nan_policy = 'omit')\n",
    "    CoV_p2 = scipy.stats.variation(condition_2[measurement], nan_policy = 'omit')\n",
    "    print(\"The coefficient of variation for {} in PLURIPOTENT cells is: \".format(measurement) + str(CoV_p1))\n",
    "    print(\"The coefficient of variation for {} in DIFF cells is: \".format(measurement) + str(CoV_p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test\n",
    "\n",
    "def ttest(measurement):\n",
    "    statistic, pvalue = scipy.stats.ttest_ind(\n",
    "        df_p1[measurement], \n",
    "        df_p2[measurement], \n",
    "        axis = 0, \n",
    "        equal_var = False, \n",
    "        nan_policy = 'omit'\n",
    "    )\n",
    "    print (\"The p-value for {} is: \".format(measurement) + str(pvalue))\n",
    "\n",
    "def ttest_binned(dependent_measurement, binned_measurement):\n",
    "    bin_list = df[binned_measurement].unique()\n",
    "    for binning in bin_list:\n",
    "        df_p1_binning = df_p1[df_p1[binned_measurement] == binning]\n",
    "        df_p2_binning = df_p2[df_p2[binned_measurement] == binning]   \n",
    "        \n",
    "        statistic, pvalue = scipy.stats.ttest_ind(\n",
    "            df_p1_binning[dependent_measurement], \n",
    "            df_p2_binning[dependent_measurement], \n",
    "            axis = 0, \n",
    "            equal_var = False, \n",
    "            nan_policy = 'omit'\n",
    "        )\n",
    "        print (\"The p-value for {} in the bin {} is: \".format(dependent_measurement, binning) + str(pvalue))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_binned(\n",
    "    \"Chromatin_Volume_um3\", \n",
    "    \"Differentiation_bins\" # binned measurement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Differentiation_bins\"]).Condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_binned(\n",
    "    \"Fraction_Tubulin_in_Spindle\", \n",
    "    \"Cell_Volume_bin\" # binned measurement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Cell_Volume_bin\"]).Condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest(\"Chromatin_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spearman_SV_TubDens = correlation(\n",
    "    dataframe_list = [df_p1, df_p2], \n",
    "    dependent_column = \"Spindle_Volume_um3\", \n",
    "    independent_column = \"Tubulin_density_spindle_norm\"\n",
    ")\n",
    "\n",
    "Spearman_SM_TubDens = correlation(\n",
    "    dataframe_list = [df_p1, df_p2], \n",
    "    dependent_column = \"Tubulin_mass_spindle_norm\", \n",
    "    independent_column = \"Tubulin_density_spindle_norm\"\n",
    ")\n",
    "Spearman_SM_TubDens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfit_SV_CV = linear_fit(\n",
    "    dataframe_list = [df_p1, df_p2], \n",
    "    dependent_column = \"Spindle_Volume_um3\", \n",
    "    independent_column = \"Cell_Volume_um3\"\n",
    ")\n",
    "\n",
    "Lfit_SM_CV = linear_fit(\n",
    "    dataframe_list = [df_p1, df_p2], \n",
    "    dependent_column = \"Tubulin_mass_spindle_norm\", \n",
    "    independent_column = \"Cell_Volume_um3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_SACV_SV_p1 = curve_fitting(\n",
    "    df[df.Condition == \"1_Pluripotent\"], \n",
    "    \"CellSurfaceArea_CellVolume_Ratio\", \n",
    "    \"Spindle_Volume_um3\"\n",
    ")\n",
    "POWER_SACV_SV_p2 = curve_fitting(\n",
    "    df[df.Condition == \"2_Differentiation\"], \n",
    "    \"CellSurfaceArea_CellVolume_Ratio\", \n",
    "    \"Spindle_Volume_um3\"\n",
    ")\n",
    "print(POWER_SACV_SV_p1, POWER_SACV_SV_p2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_SACV_SM_p1 = curve_fitting(\n",
    "    df[df.Condition == \"1_Pluripotent\"], \n",
    "    \"CellSurfaceArea_CellVolume_Ratio\", \n",
    "    \"Tubulin_mass_spindle_norm\"\n",
    ")\n",
    "POWER_SACV_SM_p2 = curve_fitting(\n",
    "    df[df.Condition == \"2_Differentiation\"], \n",
    "    \"CellSurfaceArea_CellVolume_Ratio\", \n",
    "    \"Tubulin_mass_spindle_norm\"\n",
    ")\n",
    "print(POWER_SACV_SM_p1, POWER_SACV_SM_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_TubDensity_SSR_p1 = curve_fitting(\n",
    "    df[df.Condition == \"1_Pluripotent\"], \n",
    "    \"Tubulin_density_spindle_norm\", \n",
    "    \"Fraction_SpindleVol_in_Cell\"\n",
    ")\n",
    "POWER_TubDensity_SSR_p2 = curve_fitting(\n",
    "    df[df.Condition == \"2_Differentiation\"], \n",
    "    \"Tubulin_density_spindle_norm\", \n",
    "    \"Fraction_SpindleVol_in_Cell\"\n",
    ")\n",
    "print(POWER_TubDensity_SSR_p1, POWER_TubDensity_SSR_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest(\"Tubulin_density_spindle_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for significantly different variances\n",
    "# without the need for normal distribution\n",
    "\n",
    "from scipy.stats import bartlett\n",
    "from scipy.stats import levene\n",
    "\n",
    "stat_bartlett, p_bartlett = bartlett(df_p1.Tubulin_density_spindle_norm, df_p2.Tubulin_density_spindle_norm)\n",
    "print(p_bartlett)\n",
    "\n",
    "stat_levene, p_levene = levene(df_p1.Tubulin_density_spindle_norm, df_p2.Tubulin_density_spindle_norm)\n",
    "print(stat_levene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_p1.Tubulin_density_spindle_norm.var())\n",
    "print(df_p2.Tubulin_density_spindle_norm.var())\n",
    "print(df_p1.Tubulin_density_spindle_norm.std())\n",
    "print(df_p2.Tubulin_density_spindle_norm.std())\n",
    "print(df_p1.Tubulin_density_spindle_norm.mean())\n",
    "print(df_p2.Tubulin_density_spindle_norm.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Cell_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Condition\", \"Cell_Volume_bin\"]).Cell_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Spindle_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Fraction_SpindleVol_in_Cell.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Fraction_SpindleVol_in_Cell.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Chromatin_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Chromatin_Volume_um3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Condition\", \"Cell_Volume_bin\"]).Spindle_Volume_um3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Condition\", \"Cell_Volume_bin\"]).Spindle_Volume_um3.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Condition\", \"Cell_Volume_bin\"]).Spindle_Length_um.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Condition\", \"Cell_Volume_bin\"]).Tubulin_mass_spindle_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Fraction_SpindleVol_in_Cell.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Fraction_Tubulin_in_Spindle.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Fraction_Tubulin_in_Spindle.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Tubulin_density_spindle_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Tubulin_density_spindle_norm.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Condition\").Tubulin_density_cytop_norm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation([df_p1, df_p2], \"Cell_Volume_um3\", \"Spindle_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation([df], \"Cell_Volume_um3\", \"Spindle_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation([df], \"Tubulin_mass_spindle_norm\", \"Chromatin_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation([df], \"Tubulin_mass_spindle_norm\", \"Tubulin_density_spindle_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation([df], \"Tubulin_mass_spindle_norm\", \"Spindle_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation([df], \"Tubulin_density_cytop_norm\", \"Cell_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson_correlation([df], \"Cell_Volume_um3\", \"Spindle_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import var, mean, sqrt\n",
    "from pandas import Series\n",
    "\n",
    "def cohens_d(parameter) -> float:\n",
    "    d1 = df_p1[parameter]\n",
    "    d2 = df_p2[parameter]\n",
    "    \n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = var(d1, ddof = 1), var(d2, ddof = 1)\n",
    "\n",
    "    # calculate the pooled standard deviation\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = mean(d1), mean(d2)\n",
    "\n",
    "    # return the effect size\n",
    "    return (u1 - u2) / s\n",
    "\n",
    "def cohens_d_binned(parameter, binned_parameter):\n",
    "    \n",
    "    bin_list = df[binned_parameter].unique()\n",
    "    for binning in bin_list:\n",
    "        print(binning)\n",
    "        d1 = df_p1[df_p1[binned_parameter] == binning][parameter]\n",
    "        d2 = df_p2[df_p2[binned_parameter] == binning][parameter]\n",
    "        # calculate the size of samples\n",
    "        n1, n2 = len(d1), len(d2)\n",
    "        # calculate the variance of the samples\n",
    "        s1, s2 = var(d1, ddof = 1), var(d2, ddof = 1)\n",
    "        # calculate the pooled standard deviation\n",
    "        s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "        # calculate the means of the samples\n",
    "        u1, u2 = mean(d1), mean(d2)\n",
    "        # return the effect size\n",
    "        cohens_d = ((u1 - u2) / s)\n",
    "        print(cohens_d)\n",
    "    #return cohens_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d(\"Fraction_SpindleVol_in_Cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d(\"Fraction_Tubulin_in_Spindle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d(\"Sphericity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d(\"Tubulin_density_cytop_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d(\"Tubulin_density_spindle_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d(\"Chromatin_Volume_um3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Fraction_SpindleVol_in_Cell\", \"Cell_Volume_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Fraction_SpindleVol_in_Cell\", \"Differentiation_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Sphericity\", \"Differentiation_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Cell_Volume_um3\", \"Differentiation_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Chromatin_Dilation\", \"Differentiation_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"MetaphasePlate_Width_um\", \"Differentiation_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Spindle_Volume_um3\", \"Cell_Volume_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohens_d_binned(\"Spindle_Volume_um3\", \"CellSurfaceArea_CellVolume_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df[[\"Cell_Volume_um3\", \"Differentiation_bins\", \"Condition\"]]\n",
    "df_select[\"Differentiation_bins_Condition\"] = df_select.Differentiation_bins.str.cat(df_select.Condition)\n",
    "print(df_select.Differentiation_bins_Condition.value_counts())\n",
    "df_select.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA Testing for time-resolved / binned data!\n",
    "# ANOVA as generalized linear model (GLM):\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import pingouin as pg\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "measurement = 'Sphericity'\n",
    "group_variable_string = 'Differentiation_bins'\n",
    "group_variable = group_variable_string + '_Condition'\n",
    "\n",
    "df[group_variable] = df[group_variable_string].str.cat(df.Condition)\n",
    " \n",
    "nan_elements = df[measurement].isnull()\n",
    "data = df[~nan_elements]\n",
    "\n",
    "list_of_groups = data[group_variable].unique()\n",
    "\n",
    "print(data[group_variable].value_counts())\n",
    "\n",
    "# Bartlett's test for equal variances (One-way ANOVA requires equal variances!)\n",
    "\n",
    "BartlettResult = stats.bartlett(\n",
    "    data[data[group_variable] == list_of_groups[0]][measurement], \n",
    "    data[data[group_variable] == list_of_groups[1]][measurement], \n",
    "    data[data[group_variable] == list_of_groups[2]][measurement],\n",
    "    data[data[group_variable] == list_of_groups[3]][measurement], \n",
    "    data[data[group_variable] == list_of_groups[4]][measurement], \n",
    "    data[data[group_variable] == list_of_groups[5]][measurement],\n",
    ")\n",
    "\n",
    "print(\"The Bartlett test for equal variances of {}: \".format(measurement) + str(BartlettResult))\n",
    "\n",
    "results = ols(measurement + '~ C('+ group_variable + ')', data = data).fit()\n",
    "print(results.summary())\n",
    "\n",
    "aov_table = sm.stats.anova_lm(results, typ = 2)\n",
    "\n",
    "def anova_table(aov):\n",
    "    aov['mean_sq'] = aov[:]['sum_sq'] / aov[:]['df']\n",
    "    \n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq'] / sum(aov['sum_sq'])\n",
    "    \n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df'] * aov['mean_sq'][-1])) / (sum(aov['sum_sq']) + aov['mean_sq'][-1])\n",
    "    \n",
    "    cols = ['sum_sq', 'df', 'mean_sq', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov\n",
    "\n",
    "aov_table = anova_table(aov_table)\n",
    "print(\"\\n ANOVA TABLE: \")\n",
    "print(aov_table)\n",
    "\n",
    "# Post-hoc testing\n",
    "mc = MultiComparison(data[measurement], data[group_variable])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(\"\\n\\n POST-HOC testing for {}: \\n\".format(measurement))\n",
    "print(mc_results)\n",
    "print(\"If \\\"reject\\\" = True, then H0 should be rejected\")\n",
    "\n",
    "# Welch's ANOVA when variances are unequal\n",
    "aov_table_WELCH = pg.welch_anova(dv = measurement, between = group_variable, data = data)\n",
    "print(\"\\n Welch's ANOVA table\") \n",
    "print(aov_table_WELCH)\n",
    "\n",
    "# Post-hoc testing using Games-Howell post-hoc test\n",
    "mc_results_GamesHowell = pg.pairwise_gameshowell(dv = measurement, between = group_variable, data = data)\n",
    "print(\"\\n Games-Howell post-hoc test table\") \n",
    "print(mc_results_GamesHowell)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
