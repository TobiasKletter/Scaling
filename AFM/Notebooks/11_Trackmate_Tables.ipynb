{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking\" + \"/\"\n",
    "inputFolder = root + \"Input_Tracking\" + \"/\"\n",
    "outputFolder = root + \"Output_Lineages\" + \"/\"\n",
    "\n",
    "def lineages(x, links_dataframe):\n",
    "    # Parse lineage relationships between splitting events\n",
    "    source_id = x.Source_ID # each row's source spot ID\n",
    "    # add source id to list if the row is a splitting event\n",
    "    if x.Splitting_event:\n",
    "        lineage = [str(source_id)]\n",
    "    else:\n",
    "        lineage = []\n",
    "    while True:\n",
    "        target_id = links_dataframe.loc[links_dataframe['Target_ID'] == source_id,:] # find row containing corresponding target ID\n",
    "        if target_id.empty:\n",
    "            break\n",
    "        if target_id.Splitting_event.values[0]:\n",
    "            lineage.append(str(target_id.Source_ID.values[0]))\n",
    "        source_id = target_id.Source_ID.values[0]\n",
    "    if lineage:    \n",
    "        return \".\".join(reversed(lineage)) # insert . between every element in the list, in reverse order\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_mother(x):\n",
    "    lineage_list = x.split(\".\")\n",
    "    if len(lineage_list) == 1:\n",
    "        return None\n",
    "    else:\n",
    "        return lineage_list[-2] \n",
    "\n",
    "def get_grandmother(x):\n",
    "    lineage_list = x.split(\".\")\n",
    "    if len(lineage_list) < 3:\n",
    "        return None\n",
    "    else:\n",
    "        return lineage_list[-3]     \n",
    "    \n",
    "def get_sister(x, dataframe):\n",
    "    if x.Mother_ID is None:\n",
    "        return None\n",
    "    else:\n",
    "        sister_df = dataframe.loc[\n",
    "            (dataframe.Mother_ID == x.Mother_ID) & \n",
    "            (dataframe.Position == x.Position) &\n",
    "            (dataframe.Source_ID != x.Source_ID), :\n",
    "        ]\n",
    "        if sister_df.shape[0] > 0:\n",
    "            lineage_sister = sister_df.iloc[0]['Lineage']\n",
    "            sister = lineage_sister.split(\".\")[-1]\n",
    "            return sister\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def seensister(x, already_seen_list):\n",
    "    if x.Sister_ID is None:\n",
    "            return None\n",
    "    else:\n",
    "        if x.Mother_ID in already_seen_list:\n",
    "            return True\n",
    "        else:\n",
    "            already_seen_list.append(x.Mother_ID)\n",
    "            return False\n",
    "\n",
    "def get_aunt(x, dataframe):\n",
    "    if x.Mother_ID is None:\n",
    "        return None\n",
    "    else:\n",
    "        aunt_ID = dataframe.loc[dataframe.Source_ID == int(x.Mother_ID), \"Sister_ID\"]\n",
    "        if aunt_ID is None:\n",
    "            return None\n",
    "        else:\n",
    "            return aunt_ID.item()\n",
    "\n",
    "def get_cousin(x, dataframe):\n",
    "    if x.Grandmother_ID is None:\n",
    "        return None\n",
    "    else:\n",
    "        cousins_df = dataframe.loc[\n",
    "            (dataframe.Grandmother_ID == x.Grandmother_ID) & \n",
    "            (dataframe.Source_ID != x.Source_ID) &\n",
    "            (dataframe.Mother_ID != x.Mother_ID), :\n",
    "        ]\n",
    "        cousins = []\n",
    "        if cousins_df.shape[0] == 2:   \n",
    "            cousinA = cousins_df.iloc[0, 1].item()\n",
    "            cousinB = cousins_df.iloc[1, 1].item()\n",
    "            return cousinA, cousinB\n",
    "        elif cousins_df.shape[0] == 1:\n",
    "            cousinA = cousins_df.iloc[0, 1].item()\n",
    "            return cousinA\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def get_random(x, dataframe):\n",
    "    position = x.Position\n",
    "    random_df = dataframe.loc[\n",
    "            (dataframe.Position == position) &\n",
    "            (dataframe.Track_ID != x.Track_ID) # Don't pair within same lineage\n",
    "           # (dataframe.Source_ID != x.Sister_ID) & \n",
    "           # (dataframe.Source_ID != x.Mother_ID) & \n",
    "           # (dataframe.Source_ID != x.Grandmother_ID) & \n",
    "           # (dataframe.Source_ID != x.Cousin_ID) & \n",
    "           # (dataframe.Source_ID != x.Aunt_ID), :\n",
    "        ]\n",
    "    \n",
    "    random_ID = random_df[\"Source_ID\"].sample(1)\n",
    "    return random_ID.item()\n",
    "\n",
    "def seengranny(x, granny_seen_list):\n",
    "    if x.Grandmother_ID is None:\n",
    "        return None\n",
    "    else:\n",
    "        if x.Grandmother_ID not in granny_seen_list:\n",
    "            granny_seen_list.append(x.Grandmother_ID)\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "#def getDataset(x):\n",
    "    # annotate parent dataset (important for \n",
    "    # interrupted experiments)\n",
    "#    experiment = x.Experiment\n",
    "    \n",
    "#    if experiment == \"20200725-142832\":\n",
    "#        return \"20200724\"\n",
    "#    elif experiment in [\"20200802-104739\", \"20200803-181830\"]:\n",
    "#        print(experiment)\n",
    "#        return \"20200731\"\n",
    "#    elif experiment in [\"20200809-114236\", \"20200810-225504\"]:\n",
    "#        return \"20200807\"\n",
    "#    else:\n",
    "#        return experiment.split(\"-\")[0]\n",
    "\n",
    "def correct_subexperiment(x, last_timepoint1, last_timepoint2, old_subexperiment, new_subexperiment1, new_subexperiment2):\n",
    "    timepoint = x\n",
    "    if last_timepoint2 >= timepoint > last_timepoint1:\n",
    "        return new_subexperiment1\n",
    "    elif timepoint > last_timepoint2:\n",
    "        return new_subexperiment2\n",
    "    else: \n",
    "        return old_subexperiment\n",
    "    \n",
    "def tracking_dataframes(datadir, dataset, position, outdir = outputFolder):\n",
    "    links = pd.read_csv(\n",
    "        datadir + \"{}-P000{}_Links_in_tracks_statistics.csv\".format(dataset, position),\n",
    "        usecols = ['TRACK_ID', 'SPOT_SOURCE_ID', 'SPOT_TARGET_ID']\n",
    "    )\n",
    "    links.rename(columns = {\n",
    "        \"TRACK_ID\": \"Track_ID\", \n",
    "        \"SPOT_SOURCE_ID\": \"Source_ID\", \n",
    "        \"SPOT_TARGET_ID\": \"Target_ID\"\n",
    "    }, inplace = True)\n",
    "    \n",
    "    spots = pd.read_csv(\n",
    "        datadir + \"{}-P000{}_Spots_in_tracks_statistics.csv\".format(dataset, position),\n",
    "        usecols = ['ID', 'TRACK_ID', 'POSITION_X', 'POSITION_Y', 'FRAME']\n",
    "    )\n",
    "    spots.rename(columns = {\n",
    "        \"TRACK_ID\": \"Track_ID\", \n",
    "        \"POSITION_X\": \"Track_Coordinate_X\", \n",
    "        \"POSITION_Y\": \"Track_Coordinate_Y\", \n",
    "        \"FRAME\": \"Frame\"\n",
    "    }, inplace = True)\n",
    "    \n",
    "    # Generate a list of spot_ids that correspond to a splitting event\n",
    "    # (Per definition, a splitting event is labelled twice as \"source\")\n",
    "    source_ids = list(links[\"Source_ID\"])\n",
    "    source_id_counts = Counter(source_ids)\n",
    "    splitting_event_ids = [id for id in source_id_counts if source_id_counts[id] > 1]\n",
    "    \n",
    "    # Add Boolean to Spots and Links dataframes\n",
    "    # that indicate whether the spot or links belongs to a \n",
    "    # splitting event\n",
    "\n",
    "    spots[\"Splitting_event\"] = spots[\"ID\"].apply(lambda x:\\\n",
    "                                                 False if x not in splitting_event_ids\\\n",
    "                                                 else True)\n",
    "\n",
    "    links[\"Splitting_event\"] = links[\"Source_ID\"].apply(lambda x:\\\n",
    "                                                 False if x not in splitting_event_ids\\\n",
    "                                                 else True)\n",
    "\n",
    "    \n",
    "\n",
    "    links['Lineage'] = links.apply(lineages, args = (links,), axis = 1)\n",
    "    print(\"Successfully annotated lineage information.\")\n",
    "\n",
    "    links = links[links[\"Splitting_event\"] == True]\n",
    "    spots = spots[spots[\"Splitting_event\"] == True]\n",
    "    spots.rename(columns = {\"ID\": \"Source_ID\"}, inplace = True)\n",
    "    \n",
    "    df = pd.merge(links, spots, how = \"outer\", on = [\"Source_ID\", \"Track_ID\", \"Splitting_event\"])\n",
    "    \n",
    "    df.drop([\"Target_ID\"], axis = 1, inplace = True)\n",
    "    df.drop_duplicates(subset = ['Source_ID'], inplace = True)\n",
    "    \n",
    "    df[\"Timepoint\"] = df.Frame.apply(lambda x: int(x + 1)) # Frames (Trackmate) are 0 index\n",
    "    df[\"Position\"] = position\n",
    "    df[\"Experiment\"] = dataset\n",
    "    \n",
    "    df[\"Dataset\"] = df.Experiment.str.split(\"-\").str.get(0)\n",
    "    \n",
    "    #print(df)\n",
    "    \n",
    "    if dataset == \"20200724-201611\":\n",
    "        df[\"Experiment\"] = df.Timepoint.apply(\n",
    "            correct_subexperiment, \n",
    "            last_timepoint1 = 93, \n",
    "            last_timepoint2 = 93, \n",
    "            old_subexperiment = \"20200724-201611\",\n",
    "            new_subexperiment1 = \"20200725-142832\",\n",
    "            new_subexperiment2 = \"20200725-142832\"\n",
    "        )\n",
    "\n",
    "    if dataset == \"20200731-175845\":\n",
    "        df[\"Experiment\"] = df.Timepoint.apply(\n",
    "            correct_subexperiment, \n",
    "            last_timepoint1 = 225,\n",
    "            last_timepoint2 = 374,\n",
    "            old_subexperiment = \"20200731-175845\", \n",
    "            new_subexperiment1 = \"20200802-104739\",\n",
    "            new_subexperiment2 = \"20200803-181830\"\n",
    "        )\n",
    "\n",
    "    if dataset == \"20200807-174159\":\n",
    "        df[\"Experiment\"] = df.Timepoint.apply(\n",
    "            correct_subexperiment, \n",
    "            last_timepoint1 = 199,\n",
    "            last_timepoint2 = 378,\n",
    "            old_subexperiment = \"20200807-174159\", \n",
    "            new_subexperiment1 = \"20200809-114236\",\n",
    "            new_subexperiment2 = \"20200810-225504\"\n",
    "        )\n",
    "        \n",
    "    \n",
    "    df[\"Generation\"] = df[\"Lineage\"].apply(lambda x: x.count(\".\") + 1)\n",
    "    df[\"Mother_ID\"] = df[\"Lineage\"].apply(lambda x: get_mother(x))\n",
    "    df[\"Grandmother_ID\"] = df[\"Lineage\"].apply(lambda x: get_grandmother(x))\n",
    "    df[\"Sister_ID\"] = df.apply(get_sister, dataframe = df, axis = 1)\n",
    "    \n",
    "    # Randomising order of dataframe to \n",
    "    # avoid that sisters with shortest cell cycles\n",
    "    # are 'False' for Seen_sister or seen_granny.\n",
    "    df = df.sample(frac = 1) # shuffle rows\n",
    "    \n",
    "    # This will allow to sample one cell out of sister pair\n",
    "    seen_sister_list = []\n",
    "    print(\"Populating sister list\")\n",
    "    df[\"Seen_sister\"] = df.apply(seensister, already_seen_list = seen_sister_list, axis = 1)    \n",
    "    df[\"Aunt_ID\"] = df.apply(get_aunt, dataframe = df, axis = 1)\n",
    "    df[\"Cousin_ID\"] = df.apply(get_cousin, dataframe = df, axis = 1)\n",
    "    df[\"Random_ID\"] = df.apply(get_random, dataframe = df, axis = 1)\n",
    "    \n",
    "    # This will allow to sample one cell out of cousin quartett\n",
    "    seen_granny_list = []\n",
    "    print(\"Populating granny list\")\n",
    "    df[\"Seen_granny\"] = df.apply(seengranny, granny_seen_list = seen_granny_list, axis = 1) \n",
    "    \n",
    "    # sort back to index order after shuffling\n",
    "    df = df.sort_index()\n",
    "    destination = outdir + \"{}_P{}_lineages.csv\".format(dataset, position)\n",
    "    df.to_csv(destination)\n",
    "    print(\"Successfully exported lineage dataframe to \" + destination)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20190227-182447_P1_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20190227-182447_P2_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20190618-conc_P1_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20190618-conc_P2_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20190827-181922_P1_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20190827-181922_P2_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200724-201611_P1_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200724-201611_P2_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200728-174144_P2_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200730-190931_P1_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200731-175845_P1_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200731-175845_P2_lineages.csv\n",
      "Successfully annotated lineage information.\n",
      "Populating sister list\n",
      "Populating granny list\n",
      "Successfully exported lineage dataframe to /Volumes/TOB_WD2/Data_Analysis/DataFrames/Tracking/Output_Lineages/20200807-174159_P2_lineages.csv\n"
     ]
    }
   ],
   "source": [
    "df_0227_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20190227-182447\", position = \"1\")\n",
    "df_0227_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20190227-182447\", position = \"2\")\n",
    "\n",
    "df_0618_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20190618-conc\", position = \"1\")\n",
    "df_0618_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20190618-conc\", position = \"2\")\n",
    "\n",
    "df_0827_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20190827-181922\", position = \"1\")\n",
    "df_0827_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20190827-181922\", position = \"2\")\n",
    "\n",
    "df_0724_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20200724-201611\", position = \"1\")\n",
    "df_0724_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20200724-201611\", position = \"2\")\n",
    "\n",
    "#     df_0728_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20200728-174144\", position = \"1\")\n",
    "df_0728_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20200728-174144\", position = \"2\")\n",
    "\n",
    "df_0730_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20200730-190931\", position = \"1\")\n",
    "#     df_0730_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20200730-190931\", position = \"2\")\n",
    "\n",
    "df_0731_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20200731-175845\", position = \"1\")\n",
    "df_0731_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20200731-175845\", position = \"2\")\n",
    "\n",
    "#     df_0807_p1 = tracking_dataframes(datadir = inputFolder, dataset = \"20200807-174159\", position = \"1\")\n",
    "df_0807_p2 = tracking_dataframes(datadir = inputFolder, dataset = \"20200807-174159\", position = \"2\")\n",
    "#     df_0807_p3 = tracking_dataframes(datadir = inputFolder, dataset = \"20200807-174159\", position = \"3\")\n",
    "#      df_0807_p4 = tracking_dataframes(datadir = inputFolder, dataset = \"20200807-174159\", position = \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [\n",
    "    df_0227_p1, \n",
    "    df_0227_p2, \n",
    "    df_0618_p1, \n",
    "    df_0618_p2, \n",
    "    df_0827_p1, \n",
    "    df_0827_p2, \n",
    "    df_0724_p1, \n",
    "    df_0724_p2, \n",
    "    df_0728_p2, \n",
    "    df_0730_p1, \n",
    "    df_0731_p1, \n",
    "    df_0731_p2, \n",
    "    df_0807_p2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Position</th>\n",
       "      <th>Number_of_tracks</th>\n",
       "      <th>Max_No_of_Generations</th>\n",
       "      <th>Number_of_Source_IDs</th>\n",
       "      <th>Number_of_Sister_IDs</th>\n",
       "      <th>Number_of_Cousin_IDs</th>\n",
       "      <th>Number_of_Mother_IDs</th>\n",
       "      <th>Number_of_Aunt_IDs</th>\n",
       "      <th>Number_of_Grandmother_IDs</th>\n",
       "      <th>Number_of_Random_IDs</th>\n",
       "      <th>Average_No_of_SplittingEvents_per_Track</th>\n",
       "      <th>Average_No_of_Sisters_per_Splitting_event</th>\n",
       "      <th>Average_No_of_Mothers_per_Splitting_event</th>\n",
       "      <th>Average_No_of_Grandmothers_per_Splitting_event</th>\n",
       "      <th>Average_No_of_Aunts_per_Splitting_event</th>\n",
       "      <th>Average_No_of_Cousin_per_Splitting_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190227</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>652</td>\n",
       "      <td>580</td>\n",
       "      <td>531</td>\n",
       "      <td>627</td>\n",
       "      <td>563</td>\n",
       "      <td>579</td>\n",
       "      <td>652</td>\n",
       "      <td>26.080000</td>\n",
       "      <td>0.852528</td>\n",
       "      <td>0.939052</td>\n",
       "      <td>0.825793</td>\n",
       "      <td>0.793158</td>\n",
       "      <td>0.722729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190227</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>318</td>\n",
       "      <td>238</td>\n",
       "      <td>174</td>\n",
       "      <td>264</td>\n",
       "      <td>193</td>\n",
       "      <td>203</td>\n",
       "      <td>318</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>0.588667</td>\n",
       "      <td>0.675170</td>\n",
       "      <td>0.468405</td>\n",
       "      <td>0.442557</td>\n",
       "      <td>0.390039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190618</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>654</td>\n",
       "      <td>520</td>\n",
       "      <td>490</td>\n",
       "      <td>621</td>\n",
       "      <td>537</td>\n",
       "      <td>570</td>\n",
       "      <td>654</td>\n",
       "      <td>19.818182</td>\n",
       "      <td>0.588093</td>\n",
       "      <td>0.745848</td>\n",
       "      <td>0.538699</td>\n",
       "      <td>0.496309</td>\n",
       "      <td>0.430761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190618</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>595</td>\n",
       "      <td>466</td>\n",
       "      <td>365</td>\n",
       "      <td>552</td>\n",
       "      <td>438</td>\n",
       "      <td>477</td>\n",
       "      <td>595</td>\n",
       "      <td>13.837209</td>\n",
       "      <td>0.654496</td>\n",
       "      <td>0.815113</td>\n",
       "      <td>0.614717</td>\n",
       "      <td>0.524985</td>\n",
       "      <td>0.398562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190827</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>462</td>\n",
       "      <td>400</td>\n",
       "      <td>372</td>\n",
       "      <td>436</td>\n",
       "      <td>400</td>\n",
       "      <td>406</td>\n",
       "      <td>462</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>0.523893</td>\n",
       "      <td>0.598117</td>\n",
       "      <td>0.456574</td>\n",
       "      <td>0.441421</td>\n",
       "      <td>0.413252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190827</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>8</td>\n",
       "      <td>1079</td>\n",
       "      <td>628</td>\n",
       "      <td>420</td>\n",
       "      <td>848</td>\n",
       "      <td>533</td>\n",
       "      <td>617</td>\n",
       "      <td>1079</td>\n",
       "      <td>6.096045</td>\n",
       "      <td>0.335369</td>\n",
       "      <td>0.514894</td>\n",
       "      <td>0.266064</td>\n",
       "      <td>0.213633</td>\n",
       "      <td>0.154057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200724</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>6</td>\n",
       "      <td>523</td>\n",
       "      <td>312</td>\n",
       "      <td>125</td>\n",
       "      <td>380</td>\n",
       "      <td>151</td>\n",
       "      <td>171</td>\n",
       "      <td>523</td>\n",
       "      <td>3.657343</td>\n",
       "      <td>0.456677</td>\n",
       "      <td>0.590335</td>\n",
       "      <td>0.198868</td>\n",
       "      <td>0.168232</td>\n",
       "      <td>0.132992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200724</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>455</td>\n",
       "      <td>262</td>\n",
       "      <td>114</td>\n",
       "      <td>317</td>\n",
       "      <td>150</td>\n",
       "      <td>174</td>\n",
       "      <td>455</td>\n",
       "      <td>3.297101</td>\n",
       "      <td>0.335157</td>\n",
       "      <td>0.436767</td>\n",
       "      <td>0.172388</td>\n",
       "      <td>0.140849</td>\n",
       "      <td>0.094459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200728</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2.269231</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.506410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200730</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>1.218182</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200731</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>546</td>\n",
       "      <td>468</td>\n",
       "      <td>403</td>\n",
       "      <td>526</td>\n",
       "      <td>462</td>\n",
       "      <td>490</td>\n",
       "      <td>546</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.773856</td>\n",
       "      <td>0.881867</td>\n",
       "      <td>0.758102</td>\n",
       "      <td>0.694109</td>\n",
       "      <td>0.549998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200731</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>6</td>\n",
       "      <td>303</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>146</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>303</td>\n",
       "      <td>1.929936</td>\n",
       "      <td>0.146307</td>\n",
       "      <td>0.270046</td>\n",
       "      <td>0.042682</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>0.014275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200807</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>131</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>131</td>\n",
       "      <td>2.183333</td>\n",
       "      <td>0.160397</td>\n",
       "      <td>0.355675</td>\n",
       "      <td>0.083690</td>\n",
       "      <td>0.043690</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset Position  Number_of_tracks  Max_No_of_Generations  \\\n",
       "0  20190227        1                25                      7   \n",
       "0  20190227        2                36                      5   \n",
       "0  20190618        1                33                      8   \n",
       "0  20190618        2                43                      7   \n",
       "0  20190827        1                24                      7   \n",
       "0  20190827        2               177                      8   \n",
       "0  20200724        1               143                      6   \n",
       "0  20200724        2               138                      5   \n",
       "0  20200728        2                26                      2   \n",
       "0  20200730        1               110                      2   \n",
       "0  20200731        1                20                      8   \n",
       "0  20200731        2               157                      6   \n",
       "0  20200807        2                60                      4   \n",
       "\n",
       "   Number_of_Source_IDs  Number_of_Sister_IDs  Number_of_Cousin_IDs  \\\n",
       "0                   652                   580                   531   \n",
       "0                   318                   238                   174   \n",
       "0                   654                   520                   490   \n",
       "0                   595                   466                   365   \n",
       "0                   462                   400                   372   \n",
       "0                  1079                   628                   420   \n",
       "0                   523                   312                   125   \n",
       "0                   455                   262                   114   \n",
       "0                    59                    20                     0   \n",
       "0                   134                    12                     0   \n",
       "0                   546                   468                   403   \n",
       "0                   303                    90                    20   \n",
       "0                   131                    40                     7   \n",
       "\n",
       "   Number_of_Mother_IDs  Number_of_Aunt_IDs  Number_of_Grandmother_IDs  \\\n",
       "0                   627                 563                        579   \n",
       "0                   264                 193                        203   \n",
       "0                   621                 537                        570   \n",
       "0                   552                 438                        477   \n",
       "0                   436                 400                        406   \n",
       "0                   848                 533                        617   \n",
       "0                   380                 151                        171   \n",
       "0                   317                 150                        174   \n",
       "0                    33                   0                          0   \n",
       "0                    24                   0                          0   \n",
       "0                   526                 462                        490   \n",
       "0                   146                  23                         44   \n",
       "0                    71                  14                         23   \n",
       "\n",
       "   Number_of_Random_IDs  Average_No_of_SplittingEvents_per_Track  \\\n",
       "0                   652                                26.080000   \n",
       "0                   318                                 8.833333   \n",
       "0                   654                                19.818182   \n",
       "0                   595                                13.837209   \n",
       "0                   462                                19.250000   \n",
       "0                  1079                                 6.096045   \n",
       "0                   523                                 3.657343   \n",
       "0                   455                                 3.297101   \n",
       "0                    59                                 2.269231   \n",
       "0                   134                                 1.218182   \n",
       "0                   546                                27.300000   \n",
       "0                   303                                 1.929936   \n",
       "0                   131                                 2.183333   \n",
       "\n",
       "   Average_No_of_Sisters_per_Splitting_event  \\\n",
       "0                                   0.852528   \n",
       "0                                   0.588667   \n",
       "0                                   0.588093   \n",
       "0                                   0.654496   \n",
       "0                                   0.523893   \n",
       "0                                   0.335369   \n",
       "0                                   0.456677   \n",
       "0                                   0.335157   \n",
       "0                                   0.256410   \n",
       "0                                   0.036364   \n",
       "0                                   0.773856   \n",
       "0                                   0.146307   \n",
       "0                                   0.160397   \n",
       "\n",
       "   Average_No_of_Mothers_per_Splitting_event  \\\n",
       "0                                   0.939052   \n",
       "0                                   0.675170   \n",
       "0                                   0.745848   \n",
       "0                                   0.815113   \n",
       "0                                   0.598117   \n",
       "0                                   0.514894   \n",
       "0                                   0.590335   \n",
       "0                                   0.436767   \n",
       "0                                   0.506410   \n",
       "0                                   0.090909   \n",
       "0                                   0.881867   \n",
       "0                                   0.270046   \n",
       "0                                   0.355675   \n",
       "\n",
       "   Average_No_of_Grandmothers_per_Splitting_event  \\\n",
       "0                                        0.825793   \n",
       "0                                        0.468405   \n",
       "0                                        0.538699   \n",
       "0                                        0.614717   \n",
       "0                                        0.456574   \n",
       "0                                        0.266064   \n",
       "0                                        0.198868   \n",
       "0                                        0.172388   \n",
       "0                                        0.000000   \n",
       "0                                        0.000000   \n",
       "0                                        0.758102   \n",
       "0                                        0.042682   \n",
       "0                                        0.083690   \n",
       "\n",
       "   Average_No_of_Aunts_per_Splitting_event  \\\n",
       "0                                 0.793158   \n",
       "0                                 0.442557   \n",
       "0                                 0.496309   \n",
       "0                                 0.524985   \n",
       "0                                 0.441421   \n",
       "0                                 0.213633   \n",
       "0                                 0.168232   \n",
       "0                                 0.140849   \n",
       "0                                 0.000000   \n",
       "0                                 0.000000   \n",
       "0                                 0.694109   \n",
       "0                                 0.018202   \n",
       "0                                 0.043690   \n",
       "\n",
       "   Average_No_of_Cousin_per_Splitting_event  \n",
       "0                                  0.722729  \n",
       "0                                  0.390039  \n",
       "0                                  0.430761  \n",
       "0                                  0.398562  \n",
       "0                                  0.413252  \n",
       "0                                  0.154057  \n",
       "0                                  0.132992  \n",
       "0                                  0.094459  \n",
       "0                                  0.000000  \n",
       "0                                  0.000000  \n",
       "0                                  0.549998  \n",
       "0                                  0.014275  \n",
       "0                                  0.017857  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def get_lineage_statistics(dataframelist = dataframes, outDir = outputFolder):\n",
    "    dataframes_for_concat = []\n",
    "        \n",
    "    for data in dataframelist:\n",
    "        dataset = data.loc[0, \"Dataset\"]\n",
    "        position = data.loc[0, \"Position\"]\n",
    "        max_generation = data.Generation.max()\n",
    "        No_of_source_ids = data.Source_ID.dropna().shape[0]\n",
    "        No_of_random_ids = data.Random_ID.dropna().shape[0]\n",
    "        No_of_sister_ids = data.Sister_ID.dropna().shape[0]\n",
    "        No_of_mother_ids = data.Mother_ID.dropna().shape[0]\n",
    "        No_of_aunt_ids = data.Aunt_ID.dropna().shape[0]\n",
    "        No_of_cousin_ids = data.Cousin_ID.dropna().shape[0]\n",
    "        No_of_grandmother_ids = data.Grandmother_ID.dropna().shape[0]\n",
    "        \n",
    "        list_of_tracks = data.Track_ID.unique()\n",
    "        list_of_trackSubData = []\n",
    "        for track in list_of_tracks:\n",
    "            sub_data = data.loc[data.Track_ID == track]\n",
    "            list_of_trackSubData.append(sub_data)\n",
    "\n",
    "        No_of_tracks = data.Track_ID.nunique()\n",
    "        Average_No_of_splitting_events = data.groupby(\"Track_ID\").describe().count().mean()\n",
    "\n",
    "        sister_per_split = []\n",
    "        mother_per_split = []\n",
    "        grandmother_per_split = []\n",
    "        aunt_per_split = []\n",
    "        cousins_per_split = []\n",
    "\n",
    "        for sub_data in list_of_trackSubData: \n",
    "            number_of_sister_ids = sub_data.Sister_ID.dropna().shape[0]\n",
    "            sis_per_total_splits = number_of_sister_ids / sub_data.shape[0]\n",
    "            sister_per_split.append(sis_per_total_splits)\n",
    "\n",
    "            number_of_mother_ids = sub_data.Mother_ID.dropna().shape[0]\n",
    "            mom_per_total_splits = number_of_mother_ids / sub_data.shape[0]\n",
    "            mother_per_split.append(mom_per_total_splits)\n",
    "\n",
    "            number_of_gmother_ids = sub_data.Grandmother_ID.dropna().shape[0]\n",
    "            gmom_per_total_splits = number_of_gmother_ids / sub_data.shape[0]\n",
    "            grandmother_per_split.append(gmom_per_total_splits)\n",
    "\n",
    "            number_of_aunt_ids = sub_data.Aunt_ID.dropna().shape[0]\n",
    "            aunt_per_total_splits = number_of_aunt_ids / sub_data.shape[0]\n",
    "            aunt_per_split.append(aunt_per_total_splits)\n",
    "\n",
    "            number_of_cousin_ids = sub_data.Cousin_ID.dropna().shape[0]\n",
    "            cousin_per_total_splits = number_of_cousin_ids / sub_data.shape[0]\n",
    "            cousins_per_split.append(cousin_per_total_splits)\n",
    "\n",
    "        statistics_dict = {\"Dataset\": dataset, \n",
    "                           \"Position\": position, \n",
    "                           \"Number_of_tracks\": No_of_tracks,\n",
    "                           \"Max_No_of_Generations\": max_generation,\n",
    "                           \"Number_of_Source_IDs\": No_of_source_ids,\n",
    "                           \"Number_of_Sister_IDs\": No_of_sister_ids,\n",
    "                           \"Number_of_Cousin_IDs\": No_of_cousin_ids,\n",
    "                           \"Number_of_Mother_IDs\": No_of_mother_ids,\n",
    "                           \"Number_of_Aunt_IDs\": No_of_aunt_ids,\n",
    "                           \"Number_of_Grandmother_IDs\": No_of_grandmother_ids,\n",
    "                           \"Number_of_Random_IDs\": No_of_random_ids,\n",
    "                           \"Average_No_of_SplittingEvents_per_Track\": data.shape[0] / No_of_tracks, \n",
    "                           \"Average_No_of_Sisters_per_Splitting_event\": mean(sister_per_split), \n",
    "                           \"Average_No_of_Mothers_per_Splitting_event\": mean(mother_per_split), \n",
    "                           \"Average_No_of_Grandmothers_per_Splitting_event\": mean(grandmother_per_split), \n",
    "                           \"Average_No_of_Aunts_per_Splitting_event\": mean(aunt_per_split), \n",
    "                           \"Average_No_of_Cousin_per_Splitting_event\": mean(cousins_per_split)\n",
    "                          }\n",
    "        df = pd.DataFrame(statistics_dict, index = [0])\n",
    "        dataframes_for_concat.append(df)\n",
    "    \n",
    "    final_df = pd.concat(dataframes_for_concat)\n",
    "    return final_df\n",
    "\n",
    "statistics_df = get_lineage_statistics()\n",
    "statistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving the metastatistics for tracking.\n"
     ]
    }
   ],
   "source": [
    "statistics_df.to_csv(\"/Volumes/TOB_WD2/Data_Analysis/DataFrames/MetaStatistics/MetaStatistics_TrackingLineages.csv\")\n",
    "print(\"Finished saving the metastatistics for tracking.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
